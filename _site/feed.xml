<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Starting Machine Learning</title>
    <description>In this blog, I will share my experiences in Machine Learning, Deep Learning and Algorithms for anyone who is new to this field.
</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 05 Jan 2016 22:33:34 +1100</pubDate>
    <lastBuildDate>Tue, 05 Jan 2016 22:33:34 +1100</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Welcome to Jekyll!</title>
        <description>&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Tom&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints &#39;Hi, Tom&#39; to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;http://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Fri, 01 Jan 2016 21:41:18 +1100</pubDate>
        <link>/jekyll/update/2016/01/01/welcome-to-jekyll.html</link>
        <guid isPermaLink="true">/jekyll/update/2016/01/01/welcome-to-jekyll.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Texture and Materials Classification using Deep Neural Networks</title>
        <description>&lt;p&gt;In this post, I will share my experience as a Deep Learning researcher beginner while I am working as a Research Assistant at NICTA (National ICT Australia) under Dr. Cong Phuoc Hyunh to classify Textures and Materials from images.&lt;/p&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;
&lt;p&gt;As machine learning is a data driven approach, we hence need data. There are quite a few materials and textures dataset and we use namely &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/data/dtd/&quot;&gt;Descibable Textures Dataset (DTD)&lt;/a&gt;, &lt;a href=&quot;http://people.csail.mit.edu/celiu/CVPR2010/FMD/&quot;&gt;Flickr Materials Database (FMD)&lt;/a&gt; and &lt;a href=&quot;http://opensurfaces.cs.cornell.edu/publications/minc/&quot;&gt;Materials in Context Database (MINC)&lt;/a&gt;. DTD, FMD and MINC have 47, 10 and 23 classes respectively. DTD has 120x47=5640 images, FMD has 100x10=1000 images and MINC has 2996674 patches. DTD and FMD has equal number of images per class while MINC all classes have different number of images. For instance, Wood has over half a million patches, while Wallpaper has just over 14000 images.&lt;/p&gt;

&lt;h2 id=&quot;hardware&quot;&gt;Hardware&lt;/h2&gt;
&lt;p&gt;It is often said more data beats better algorithms. Hence, deep learning is able to exploit lots of data to reveal patterns in the data. Hence to take advantage of this massive amount of data, we need parallel GPU computing. In our case, we used a Tesla K40 and GTX 980 GPU which have 12 GB and 4 GB VRAM respectively.&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Jan 2016 21:41:18 +1100</pubDate>
        <link>/deep/learning/2016/01/01/Texture-and-Pattern-Classification.html</link>
        <guid isPermaLink="true">/deep/learning/2016/01/01/Texture-and-Pattern-Classification.html</guid>
        
        
        <category>Deep</category>
        
        <category>Learning</category>
        
      </item>
    
  </channel>
</rss>
